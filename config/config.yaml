# IoT Personal Home Security - Configuration
# ==========================================

# Application Settings
app:
  name: "IoT Home Security"
  version: "0.1.0"
  debug: false
  log_level: "INFO"

# API Settings
api:
  enabled: true
  host: "0.0.0.0"
  port: 8000
  # CORS origins - set to specific origins in production
  # For local network use: ["http://192.168.1.*:*", "http://localhost:*"]
  cors_origins: ["*"]
  # Authentication (modular - can be extended later)
  auth:
    enabled: false
    # Future: api_key, jwt, oauth2
    method: "none"

# Database Settings
database:
  # SQLite database for face metadata and embeddings
  faces_db: "data/faces.db"
  # Enable WAL mode for better concurrent access
  wal_mode: true

# Face Detection Settings
face_detection:
  enabled: true
  model: "opencv_dnn"  # Options: haar_cascade, mediapipe, opencv_dnn, dlib, dlib_cnn
  confidence_threshold: 0.8
  min_face_size: [30, 30]
  scale_factor: 1.1
  min_neighbors: 5

# Face Recognition Settings
face_recognition:
  enabled: true
  # Embedding backend: opencv_dnn (128D, default), dlib (128D, requires dlib), tflite (512D)
  model: "opencv_dnn"  # Options: opencv_dnn, dlib, tflite, mobilenetv2
  embedding_size: 128  # 128 for opencv_dnn/dlib, 512 for tflite
  similarity_threshold: 0.6
  watch_list_dir: "data/raw/faces/watch_list"
  # Upload directory for API-uploaded faces
  upload_dir: "data/raw/faces/uploads"
  # TFLite model path (required if model: tflite)
  tflite_model_path: "data/models/face_recognition/mobilefacenet.tflite"
  
# Sound Classification Settings
sound_classification:
  enabled: true
  model: "mobilenet_audio"  # Options: mobilenet_audio, yamnet, custom_cnn
  sample_rate: 44100
  duration_seconds: 5
  confidence_threshold: 0.7
  # Security-relevant sound classes to detect
  target_classes:
    - "glass_breaking"
    - "door_wood_knock"
    - "dog"
    - "siren"
    - "crying_baby"
    - "footsteps"
    - "car_horn"

# Camera Settings
camera:
  enabled: true
  resolution: [640, 480]
  fps: 30
  device_id: 0  # 0 for default camera, or specific device path
  flip_horizontal: false
  flip_vertical: false

# Microphone Settings
microphone:
  enabled: true
  sample_rate: 44100
  channels: 1
  chunk_size: 1024
  device_index: null  # null for default device

# Motion Sensor (PIR) Settings
motion_sensor:
  enabled: true
  gpio_pin: 17
  sensitivity: "high"  # Options: low, medium, high
  cooldown_seconds: 5

# Alert Settings
alerts:
  # Local alarm (buzzer/speaker)
  local_alarm:
    enabled: true
    gpio_pin: 18
    duration_seconds: 10
  
  # Push notifications
  push_notifications:
    enabled: false
    service: "firebase"  # Options: firebase, pushover, custom
    firebase_config: "config/firebase_config.json"
  
  # SMS notifications
  sms_notifications:
    enabled: false
    service: "twilio"
    phone_numbers: []
  
  # MQTT for IoT hub integration
  mqtt:
    enabled: false
    broker: "localhost"
    port: 1883
    topic: "home/security/alerts"
    username: null
    password: null

# Model Paths
models:
  face_detection: "data/models/face_detection/haarcascade_frontalface_default.xml"
  face_recognition: "data/models/face_recognition/facenet.tflite"
  sound_classification: "data/models/sound_classification/audio_classifier.tflite"

# Data Directories
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  models_dir: "data/models"
  logs_dir: "logs"

# Raspberry Pi Specific Settings
raspberry_pi:
  use_picamera: true
  gpio_enabled: true
  optimize_for_edge: true
  use_tflite: true

# ============================================================
# Processing Constants (extracted from source code)
# ============================================================

# Face Processing Constants
face_processing:
  # Margin around detected face as fraction of size (0.2 = 20%)
  crop_margin_ratio: 0.2
  # Output size for face alignment [width, height]
  alignment_output_size: [112, 112]
  # Target size for preprocessing before embedding [width, height]
  preprocess_target_size: [160, 160]
  # Normalization values for face preprocessing
  normalization_mean: 0.5
  normalization_std: 0.5
  # Face quality score calculation
  quality:
    # Divisor for Laplacian variance to compute sharpness (higher = less sensitive)
    sharpness_divisor: 500.0
    # Target brightness (0.5 = middle gray)
    brightness_target: 0.5
    # Scale factor for brightness deviation penalty
    brightness_scale: 2.0

# DNN Detection Constants
dnn_detection:
  # Input size for SSD face detector [width, height]
  input_size: [300, 300]
  # Mean values for blob normalization (BGR order)
  mean_values: [104.0, 177.0, 123.0]
  # Default confidence threshold for detections
  confidence_threshold: 0.7
  # Non-maximum suppression threshold
  nms_threshold: 0.15
  # Minimum face size in pixels [width, height]
  min_face_size: [30, 30]
  # Aspect ratio constraints for valid face boxes
  min_aspect_ratio: 0.5
  max_aspect_ratio: 2.0
  # Maximum face size as fraction of image (0.8 = 80%)
  max_size_ratio: 0.8
  # Overlap threshold for removing duplicate detections
  overlap_threshold: 0.6

# OpenFace Embedding Constants
openface:
  # Input size for OpenFace network [width, height]
  input_size: [96, 96]
  # Ratio of similarity_threshold for partial match (threat profile)
  threat_profile_threshold_ratio: 0.7

# Audio Processing Constants
audio_processing:
  # Default sample rate for audio processing
  sample_rate: 22050
  # Default audio clip duration in seconds
  duration: 5.0
  # Threshold for silence detection
  silence_threshold: 0.01
  # Top dB for trimming silence (librosa)
  trim_top_db: 20
  # Feature extraction defaults
  features:
    n_mfcc: 40
    n_mels: 128
    n_fft: 2048
    hop_length: 512
    power: 2.0
    log_epsilon: 1.0e-10
  # Dummy classifier thresholds (when no model loaded)
  dummy_classifier:
    loud_threshold: 0.5
    ambient_threshold: 0.1
    default_confidence: 0.5
